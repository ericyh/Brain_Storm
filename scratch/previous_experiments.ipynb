{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f4b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from litellm import completion\n",
    "from datasets import load_dataset\n",
    "\n",
    "USER_PROFILE = {\n",
    "    \"location\": \"Cambridge, UK\",\n",
    "    \"background\": \"Master's in Machine Learning, Australian citizen, family in China, girlfriend from Thailand, soon to be quant researcher\",\n",
    "    \"skills\": [\"Python\", \"Chinese\", \"Machine Learning\", \"Statistics\", \"Web Crawling\", \"Quant research\", \"Data Analysis\", \"Digital electronics\", \"Arduino and Raspberry Pis\", \"Tutoring\", \"Manufacturing\", \"Soldering\", \"Engineering\", \"Fishing\", \"Machining\", \"Mushroom Foraging\", \"Coral Aquaculture\", \"Baking\", \"Importing/Exporting\",\"Gardening\"],\n",
    "    \"assets\": \"About 1-2k pounds initially, access to network of engineers, startup founders, friends in China, Thailand, Singapore and Australia\",\n",
    "}\n",
    "\n",
    "MODELS = [\n",
    "    \"openai/gpt-4o\",\n",
    "    \"google/gemini-2.0-flash\",\n",
    "]\n",
    "\n",
    "def get_profile_with_skill_subset(n_skills=5):\n",
    "    \"\"\"Returns the full profile with a randomized subset of skills.\"\"\"\n",
    "    # Ensure we don't try to sample more skills than exist\n",
    "    k = min(n_skills, len(USER_PROFILE[\"skills\"]))\n",
    "    \n",
    "    # Create the output dictionary\n",
    "    profile_subset = USER_PROFILE.copy()\n",
    "    profile_subset[\"skills\"] = random.sample(USER_PROFILE[\"skills\"], k)\n",
    "    \n",
    "    return profile_subset\n",
    "\n",
    "print(\"‚ö° Initializing Nemotron-USA Persona Stream...\")\n",
    "ds = load_dataset(\"nvidia/Nemotron-Personas-USA\", split=\"train\", streaming=True)\n",
    "ds_iter = iter(ds.shuffle(buffer_size=10000))\n",
    "\n",
    "def get_real_nemotron_persona():\n",
    "    item = next(ds_iter)\n",
    "    identity = (\n",
    "        f\"Occupation: {item['occupation']}. \"\n",
    "        f\"Persona: {item['persona']}. \"\n",
    "        f\"Traits: Age {item['age']}, Sex {item['sex']}, Education {item['education_level']}, Marital Status {item['marital_status']}.\"\n",
    "        f\"Skills: {item['skills_and_expertise']}. \"\n",
    "        f\"Hobbies: {item['hobbies_and_interests']}.\"\n",
    "    )\n",
    "    return {\"name\": f\"Citizen_{random.randint(100, 999)}\", \"prompt\": identity}\n",
    "\n",
    "LENSES = [\n",
    "    {\"name\": \"Economic Viability\", \"prompt\": \"Analyze unit economics, market size, and ROI.\"},\n",
    "    {\"name\": \"Technical Feasibility\", \"prompt\": \"Analyze if the founder's skills can actually build this. Be brutally honest and critical.\"},\n",
    "    {\"name\": \"Ease of Realisation\", \"prompt\": \"Analyze how likely the idea will actually succeed with a small starting cost. Be brutally honest and critical.\"},\n",
    "    {\"name\": \"Potential Problems\", \"prompt\": \"Analyze all the potential problems with this idea. Be brutally honest and critical.\"},\n",
    "    {\"name\": \"Market Competition\", \"prompt\": \"Analyze whether the market is already saturated with alternatives.\"},\n",
    "    {\"name\": \"Identify Most Grounded\", \"prompt\": \"Identify the most grounded, realistic and viable ideas from the list of ideas.\"}\n",
    "]\n",
    "\n",
    "def run_triple_rotation_factory(max_rounds=12):\n",
    "    discussion = []\n",
    "    \n",
    "    for r in range(1, max_rounds + 1):\n",
    "        is_persona_round = not (r % 3 == 2) # Every 3rd round is a lens round, the rest are persona seeding rounds\n",
    "        mode_label = \"üé≠ PERSONA SEEDING\" if is_persona_round else \"üîç LENS FILTERING\"\n",
    "        \n",
    "        print(f\"\\n--- ROUND {r} [{mode_label}] ---\")\n",
    "        \n",
    "        current_squad = [get_real_nemotron_persona() for _ in range(4)] if is_persona_round else LENSES\n",
    "\n",
    "        for agent in current_squad:\n",
    "            context = \"\\n\".join(discussion[-16:]) # Rolling context window\n",
    "            \n",
    "            if is_persona_round:\n",
    "                if r <= 2:\n",
    "                    instruction = (\n",
    "                        f\"Given the founder's profile ({get_profile_with_skill_subset()}), generate as many new business ideas as possible.\"\n",
    "                        \"Ideas have to be highly likely to actually work in the real world, and as simple as possible to get started with under ¬£2k.\"\n",
    "                        \"Try to focus on buying and selling something.\"\n",
    "                    )\n",
    "                else:\n",
    "                    instruction = (\n",
    "                        f\"Given the previous ideas generated and the founder's profile ({get_profile_with_skill_subset()}), \"\n",
    "                        \"Find weaknesses of previous ideas and generate/refine as many new business ideas as possible.\"\n",
    "                        \"Ideas have to be highly likely to actually work in the real world, and as simple as possible to get started with under ¬£2k.\"\n",
    "                        \"Try to focus on buying and selling something.\"\n",
    "                    )\n",
    "\n",
    "            else:\n",
    "                instruction = (\n",
    "                    f\"Critique all previous ideas using the {agent['name']} lens. \"\n",
    "                    f\"Filter out anything that is not feasible for the founder: {USER_PROFILE}. \"\n",
    "                    \"Only allow the most viable, high-potential ideas to remain.\"\n",
    "                )\n",
    "\n",
    "            sys_prompt = f\"{agent['prompt']}\\n{instruction}\"\n",
    "            \n",
    "            response = completion(\n",
    "                model=random.sample(MODELS, 1)[0],\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                    {\"role\": \"user\", \"content\": f\"History:\\n{context}\\n\\nYour contribution:\"}\n",
    "                ],\n",
    "                temperature=1.2 if is_persona_round else 0.3 \n",
    "            )\n",
    "            \n",
    "            ans = response.choices[0].message.content\n",
    "            label = agent.get('name', \"Agent\")\n",
    "            print(f\"‚úÖ [{label}]: {ans}...\")\n",
    "            discussion.append(f\"[{label}]: {ans}\")\n",
    "\n",
    "    summary = completion(\n",
    "        model=\"openai/gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"You are an analyst. Based on the 12-round debate, identify the single most viable business for this founder with the highest probability of actually succeeding in the real world: {USER_PROFILE}.\"},\n",
    "            {\"role\": \"user\", \"content\": \"\\n\".join(discussion)}\n",
    "        ],\n",
    "        temperature=0\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    return summary\n",
    "\n",
    "print(\"\\nüèÜ FINAL BUSINESS CASE:\\n\", run_triple_rotation_factory(max_rounds=12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
